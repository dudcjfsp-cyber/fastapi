import os
import base64
import logging
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from google import genai
from fastmcp import Client
import uvicorn

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œê¹… ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
current_dir = os.path.dirname(os.path.abspath(__file__))
load_dotenv(os.path.join(current_dir, ".env"))

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
MCP_SERVER_URL = "http://localhost:8002/sse"

if not GEMINI_API_KEY:
    logger.warning("âš ï¸ GEMINI_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FastAPI ì•± ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(title="AI Stylist API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

SYSTEM_INSTRUCTION = """\
ë‹¹ì‹ ì€ ìµœê³ ì˜ AI íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

[ì‘ì—… íë¦„]
1. ë¨¼ì € ì œê³µëœ ë„êµ¬(tools)ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ íŒ€ì›ì˜ ì •ë³´(ì´ë¦„, ì„±ë³„, ìŠ¤íƒ€ì¼, ì§€ì—­)ë¥¼ ì¡°íšŒí•˜ì„¸ìš”.
2. ì¡°íšŒí•œ ì •ë³´ì™€ ì‚¬ìš©ìê°€ ì œê³µí•œ ì¡°ê±´(ë‚ ì”¨, ê³„ì ˆ, ìš”ì¼ ë“±)ì„ ì¢…í•©í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜·ì°¨ë¦¼ì„ ì¶”ì²œí•˜ì„¸ìš”.
3. ì¶”ì²œì€ í•­ìƒ êµ¬ì²´ì ì´ê³  ê°ê°ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. (ì˜ˆ: "ë„¤ì´ë¹„ ìš¸ ì½”íŠ¸ + í¬ë¦¼ìƒ‰ í„°í‹€ë„¥ + ìŠ¬ë¦¼í• ë¸”ë™ íŒ¬ì¸ ")

[ê·œì¹™]
- íŒ€ì› ì •ë³´ ì¡°íšŒ ì‹œ ë°˜ë“œì‹œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- íŒ¨ì…˜ ì¶”ì²œì€ ì¡°íšŒí•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì°½ì˜ì ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.
- í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ChatRequest(BaseModel):
    query: str
    include_image: bool = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini í´ë¼ì´ì–¸íŠ¸ (ì „ì—­ ì‹±ê¸€í†¤)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
gemini_client = genai.Client(api_key=GEMINI_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëª¨ë¸ ì„ íƒ ë¡œì§ (agent.pyì˜ get_best_model ì´ì‹)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PREFERRED_MODELS = [
    "gemini-2.5-flash",
    "gemini-2.0-flash",
    "gemini-1.5-flash",
    "gemini-1.5-pro",
    "gemini-flash-latest",
]

async def get_best_model() -> str:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¤‘ ìš°ì„ ìˆœìœ„ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    logger.info("ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ê²€ìƒ‰ ì¤‘...")
    try:
        available = []
        all_models_pager = await gemini_client.aio.models.list()
        async for m in all_models_pager:
            # ìƒˆ SDK(google-genai)ì™€ êµ¬ SDK(google-generativeai) í˜¸í™˜
            methods = getattr(m, 'supported_generation_methods', None) or []
            model_id = m.name.replace("models/", "") if hasattr(m, 'name') else str(m)

            # generateContent ì§€ì› ëª¨ë¸ë§Œ í•„í„°ë§
            # ìƒˆ SDKì—ì„œ ì†ì„±ì´ ì—†ìœ¼ë©´ ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ gemini ëª¨ë¸ ìˆ˜ì§‘
            if methods:
                if 'generateContent' in methods:
                    available.append(model_id)
            elif 'gemini' in model_id.lower():
                available.append(model_id)

        logger.info(f"ğŸ“‹ ê²€ìƒ‰ëœ ëª¨ë¸: {available}")

        # ìš°ì„ ìˆœìœ„ ëª©ë¡ì—ì„œ ë¨¼ì € ë§¤ì¹­ë˜ëŠ” ëª¨ë¸ ì„ íƒ
        for pref in PREFERRED_MODELS:
            if pref in available:
                logger.info(f"âœ¨ ì„ íƒëœ ëª¨ë¸: {pref}")
                return pref

        # ìš°ì„ ìˆœìœ„ì— ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸
        if available:
            logger.warning(f"âš ï¸ ìš°ì„ ìˆœìœ„ ëª¨ë¸ ì—†ìŒ. ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš©: {available[0]}")
            return available[0]

    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    logger.warning("âš ï¸ ê¸°ë³¸ ëª¨ë¸ë¡œ fallback: gemini-2.0-flash")
    return "gemini-2.0-flash"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# API ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """Reactì—ì„œ ì§ˆë¬¸ì„ ë°›ì•„ Gemini Agentë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    logger.info(f"ğŸ“¨ ìš”ì²­ ë°›ìŒ: {request.query} (ì´ë¯¸ì§€: {request.include_image})")

    try:
        mcp_client = Client(MCP_SERVER_URL)

        async with mcp_client:
            logger.info("âœ… MCP ì„œë²„ ì—°ê²° ì„±ê³µ")
            session = mcp_client.session

            # (1) í…ìŠ¤íŠ¸ ìƒì„± â”€ ë™ì  ëª¨ë¸ ì„ íƒ
            selected_model = await get_best_model()
            response = await gemini_client.aio.models.generate_content(
                model=selected_model,
                contents=request.query,
                config=genai.types.GenerateContentConfig(
                    system_instruction=SYSTEM_INSTRUCTION,
                    temperature=0,
                    tools=[session],
                ),
            )
            response_text = response.text
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ (ëª¨ë¸: {selected_model}, ê¸¸ì´: {len(response_text or '')})")

            # (2) ì´ë¯¸ì§€ ìƒì„± (ì„ íƒì )
            generated_image_b64 = None
            if request.include_image:
                try:
                    logger.info("ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì‹œë„ (imagen-3.0-generate-001)...")
                    image_response = await gemini_client.aio.models.generate_images(
                        model="imagen-3.0-generate-001",
                        prompt=f"Fashion illustration, full body outfit: {response_text[:300]}",
                        config=genai.types.GenerateImagesConfig(
                            number_of_images=1,
                        ),
                    )
                    if image_response.generated_images:
                        raw = image_response.generated_images[0].image.image_bytes
                        generated_image_b64 = base64.b64encode(raw).decode("utf-8")
                        logger.info("âœ… ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ")
                except Exception as img_err:
                    logger.error(f"âš ï¸ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ (í…ìŠ¤íŠ¸ëŠ” ì •ìƒ ë°˜í™˜): {img_err}")

            return {"response": response_text, "image": generated_image_b64}

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ìš©"""
    return {"status": "ok", "mcp_server": MCP_SERVER_URL}


if __name__ == "__main__":
    logger.info("ğŸš€ AI Stylist API ì„œë²„ ì‹œì‘ (í¬íŠ¸: 8004)")
    uvicorn.run(app, host="0.0.0.0", port=8004)
